{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84bc062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import lottery_ticket_pruner\n",
    "from lottery_ticket_pruner import LotteryTicketPruner, PrunerCallback\n",
    "from mine import MINE\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[2]: loading MNIST data for training\n",
    "\n",
    "\n",
    "# Load the MNIST dataset using TensorFlow\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape data as 2D numpy arrays\n",
    "# convert to float32 and normalize grayscale for better num. representation\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# The tutorial reserved 10.000 training samples for validation, we change to 5.000 \n",
    "# as that is what Frankle and Carbin did in their paper\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "y_train_1hot = keras.utils.to_categorical(y_train, num_classes=10) # need y_train in a 1-hot encoded array for mine\n",
    "\n",
    "\n",
    "# In[3]: Hyperparameters for the experiment\n",
    "\n",
    "epochs_LT = 6 # epochs for the tickets, 5.45 epochs for about 5000 iterations, which is early-stop iteration in Frankle et al. paper\n",
    "batch_size_LT = 60 # mini-batch size for the tickets\n",
    "batch_size_mine = 100 # batch size for MINE algorithm\n",
    "epochs_mine = 100 # epochs for MINE algorithm\n",
    "validation_split = 1/11 # 5000 val 55000 train data\n",
    "input_dim = 784 # input_distribution dim. for MINE, also dim. size of MNIST input\n",
    "d1_dim = 300 # first hidden layer size for lottery ticket model, also first hidden layer activation distribution dim. for MINE\n",
    "d2_dim = 100  # second hidden layer size for lottery ticket model, also second hidden layer activation distribution dim. for MINE\n",
    "o_dim = 10 # output layer size for lottery ticket model, also output layer distribution dim. for MINE\n",
    "pruning_rate = 0.2 # pruning rate for LTH iterative Pruning -> removes pruning_rate% of lowest magnitude weights in an iteration\n",
    "pruning_iterations = 15  # number of iterations for applying the pruning rate iteratively -> 1 time : 20% sparse, 24 times : ~99.5% sparse\n",
    "averaging_iterations = 1 # Frankle et al. usually use average of 5 trials\n",
    "# we train this script as singular runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5086a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # clearing backend right at start, just in case\n",
    "\n",
    "inputs = keras.Input(shape=(input_dim,), name=\"digits\") # Functional build of a 2-hidden layer fully connected MLP\n",
    "x = layers.Dense(d1_dim, activation=\"ReLU\", name=\"dense_1\")(inputs) # methods made no mention of the activaton function specifically\n",
    "x = layers.Dense(d2_dim, activation=\"ReLU\", name=\"dense_2\")(x) # ReLU is standard, as all available implementations seem to use it too\n",
    "outputs = layers.Dense(o_dim, activation=\"softmax\", name=\"predictions\")(x)  # softmax activation for multi-class classification\n",
    "\n",
    "base_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "# loading the saved initialization\n",
    "base_model.load_weights(\"init_weights_fs.h5\")\n",
    "init_model = keras.models.clone_model(base_model)\n",
    "init_weights = init_model.get_weights() # init weights for Lotter Ticket reset to initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a501a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.11849876,  0.08326044,  0.03046269, ...,  0.00832217,\n",
       "         -0.03234859,  0.02240524],\n",
       "        [-0.05200388, -0.11659102,  0.11483195, ...,  0.04681451,\n",
       "         -0.09298775,  0.04070682],\n",
       "        [ 0.07204082,  0.11276603,  0.06366249, ..., -0.03666466,\n",
       "         -0.03787875,  0.02010769],\n",
       "        ...,\n",
       "        [ 0.06125017, -0.11605567, -0.05846643, ...,  0.10483941,\n",
       "         -0.04802044, -0.09744417],\n",
       "        [ 0.0922941 ,  0.08039788, -0.10164817, ..., -0.0538088 ,\n",
       "          0.04122659, -0.08141087],\n",
       "        [ 0.06768062, -0.10923558, -0.01338455, ..., -0.03052533,\n",
       "          0.0835809 , -0.06167452]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3e0a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.09970823, -0.02305449,  0.11002179, ..., -0.11474014,\n",
       "         -0.05269753,  0.03375185],\n",
       "        [ 0.06214058, -0.02567535,  0.12043392, ...,  0.09188355,\n",
       "         -0.10343234,  0.00736142],\n",
       "        [-0.04803406, -0.02286296,  0.0575523 , ...,  0.10050128,\n",
       "          0.0285947 ,  0.12061263],\n",
       "        ...,\n",
       "        [ 0.10425439, -0.05459931, -0.03847858, ..., -0.04969621,\n",
       "         -0.09415815, -0.05277631],\n",
       "        [-0.10485386,  0.03297601, -0.05529372, ..., -0.11328057,\n",
       "         -0.08493343,  0.11632317],\n",
       "        [ 0.02431818,  0.01961897, -0.05147316, ..., -0.03757758,\n",
       "          0.10760636, -0.04880322]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df02392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
